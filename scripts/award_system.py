#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªå‹•è©•é¸ç³»çµ±
ç”¨æ–¼è‡ªå‹•è©•é¸æœˆåº¦è²¢ç»çé …

ä½œè€…: Tsext Adventure Team
æˆæ¬Š: MIT License
"""

import os
import json
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import logging
import sys

# æ·»åŠ  scripts ç›®éŒ„åˆ° Python è·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

from monthly_stats import MonthlyStatsAnalyzer
from github_api import GitHubAPI

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AwardSystem:
    """çé …è©•é¸ç³»çµ±"""
    
    def __init__(self, github_api: GitHubAPI, owner: str, repo: str):
        self.github_api = github_api
        self.owner = owner
        self.repo = repo
        self.analyzer = MonthlyStatsAnalyzer(github_api, owner, repo)
        
        # çé …é…ç½®
        self.award_categories = {
            'best_story': {
                'name': 'ğŸ­ æœ€ä½³åŠ‡æƒ…ç',
                'description': 'æœ€æœ‰å‰µæ„çš„æ•…äº‹å…§å®¹',
                'weight': 3.0,
                'keywords': ['story', 'scene', 'content', 'åŠ‡æƒ…', 'å ´æ™¯', 'çµå±€', 'ending']
            },
            'technical_innovation': {
                'name': 'ğŸ› ï¸ æŠ€è¡“å‰µæ–°ç',
                'description': 'æœ€ä½³æŠ€è¡“æ”¹é€²',
                'weight': 2.0,
                'keywords': ['feature', 'enhancement', 'åŠŸèƒ½', 'æ”¹é€²', 'optimization', 'performance']
            },
            'bug_hunter': {
                'name': 'ğŸ› Bugçµäººç',
                'description': 'ç™¼ç¾å’Œä¿®å¾©æœ€å¤šå•é¡Œ',
                'weight': 2.0,
                'keywords': ['bug', 'fix', 'ä¿®å¾©', 'éŒ¯èª¤', 'issue', 'problem']
            },
            'design_master': {
                'name': 'ğŸ¨ è¨­è¨ˆå¤§å¸«ç',
                'description': 'æœ€ä½³UI/UXæ”¹é€²',
                'weight': 2.0,
                'keywords': ['ui', 'design', 'interface', 'ç•Œé¢', 'è¨­è¨ˆ', 'css', 'html']
            },
            'community_star': {
                'name': 'ğŸŒŸ ç¤¾å€ä¹‹æ˜Ÿ',
                'description': 'æœ€ç†±å¿ƒå¹«åŠ©æ–°æ‰‹çš„è²¢ç»è€…',
                'weight': 1.0,
                'keywords': ['help', 'support', 'å¹«åŠ©', 'æ”¯æ´', 'question', 'answer']
            },
            'consistency_champion': {
                'name': 'ğŸ”¥ æŒçºŒè²¢ç»ç',
                'description': 'æœ€æŒçºŒç©©å®šçš„è²¢ç»è€…',
                'weight': 1.5,
                'keywords': []
            },
            'collaboration_hero': {
                'name': 'ğŸ¤ å”ä½œè‹±é›„ç',
                'description': 'æœ€å–„æ–¼å”ä½œçš„è²¢ç»è€…',
                'weight': 1.5,
                'keywords': []
            }
        }
    
    def evaluate_monthly_awards(self, days: int = 30) -> Dict:
        """è©•é¸æœˆåº¦çé …"""
        logger.info(f"é–‹å§‹è©•é¸éå» {days} å¤©çš„æœˆåº¦çé …...")
        
        # ç²å–æœˆåº¦åˆ†ææ•¸æ“š
        analysis = self.analyzer.analyze_monthly_contributions(days)
        contributors = analysis['contributor_stats']
        
        # è©•é¸å„é¡çé …
        awards = {}
        
        for award_id, award_config in self.award_categories.items():
            logger.info(f"è©•é¸ {award_config['name']}...")
            winner = self._evaluate_award(award_id, award_config, contributors, analysis)
            if winner:
                awards[award_id] = winner
        
        # ç”Ÿæˆè©•é¸å ±å‘Š
        report = self._generate_award_report(awards, analysis)
        
        return {
            'period': analysis['period'],
            'awards': awards,
            'report': report,
            'analysis': analysis
        }
    
    def _evaluate_award(self, award_id: str, award_config: Dict, 
                       contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸å–®å€‹çé …"""
        
        if award_id == 'best_story':
            return self._evaluate_story_award(contributors, analysis)
        elif award_id == 'technical_innovation':
            return self._evaluate_technical_award(contributors, analysis)
        elif award_id == 'bug_hunter':
            return self._evaluate_bug_hunter_award(contributors, analysis)
        elif award_id == 'design_master':
            return self._evaluate_design_award(contributors, analysis)
        elif award_id == 'community_star':
            return self._evaluate_community_award(contributors, analysis)
        elif award_id == 'consistency_champion':
            return self._evaluate_consistency_award(contributors, analysis)
        elif award_id == 'collaboration_hero':
            return self._evaluate_collaboration_award(contributors, analysis)
        
        return None
    
    def _evaluate_story_award(self, contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸æœ€ä½³åŠ‡æƒ…ç"""
        story_scores = {}
        
        for author, stats in contributors.items():
            if stats['story_content'] > 0:
                # æ•…äº‹å…§å®¹æ¬Šé‡æ›´é«˜
                score = stats['story_content'] * 3.0 + stats['total_score'] * 0.1
                story_scores[author] = {
                    'score': score,
                    'story_count': stats['story_content'],
                    'total_contributions': stats['prs'] + stats['issues']
                }
        
        if not story_scores:
            return None
        
        winner = max(story_scores.items(), key=lambda x: x[1]['score'])
        
        return {
            'winner': winner[0],
            'score': winner[1]['score'],
            'details': winner[1],
            'category': 'best_story'
        }
    
    def _evaluate_technical_award(self, contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸æŠ€è¡“å‰µæ–°ç"""
        tech_scores = {}
        
        for author, stats in contributors.items():
            if stats['technical_improvements'] > 0:
                # æŠ€è¡“æ”¹é€²æ¬Šé‡
                score = stats['technical_improvements'] * 2.0 + stats['merged_prs'] * 1.5
                tech_scores[author] = {
                    'score': score,
                    'tech_count': stats['technical_improvements'],
                    'merged_prs': stats['merged_prs']
                }
        
        if not tech_scores:
            return None
        
        winner = max(tech_scores.items(), key=lambda x: x[1]['score'])
        
        return {
            'winner': winner[0],
            'score': winner[1]['score'],
            'details': winner[1],
            'category': 'technical_innovation'
        }
    
    def _evaluate_bug_hunter_award(self, contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸Bugçµäººç"""
        bug_scores = {}
        
        for author, stats in contributors.items():
            if stats['bug_fixes'] > 0:
                # Bugä¿®å¾©æ¬Šé‡
                score = stats['bug_fixes'] * 2.0 + stats['merged_prs'] * 1.0
                bug_scores[author] = {
                    'score': score,
                    'bug_count': stats['bug_fixes'],
                    'merged_prs': stats['merged_prs']
                }
        
        if not bug_scores:
            return None
        
        winner = max(bug_scores.items(), key=lambda x: x[1]['score'])
        
        return {
            'winner': winner[0],
            'score': winner[1]['score'],
            'details': winner[1],
            'category': 'bug_hunter'
        }
    
    def _evaluate_design_award(self, contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸è¨­è¨ˆå¤§å¸«ç"""
        design_scores = {}
        
        for author, stats in contributors.items():
            if stats['ui_improvements'] > 0:
                # UIæ”¹é€²æ¬Šé‡
                score = stats['ui_improvements'] * 2.0 + stats['total_score'] * 0.1
                design_scores[author] = {
                    'score': score,
                    'ui_count': stats['ui_improvements'],
                    'total_contributions': stats['prs'] + stats['issues']
                }
        
        if not design_scores:
            return None
        
        winner = max(design_scores.items(), key=lambda x: x[1]['score'])
        
        return {
            'winner': winner[0],
            'score': winner[1]['score'],
            'details': winner[1],
            'category': 'design_master'
        }
    
    def _evaluate_community_award(self, contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸ç¤¾å€ä¹‹æ˜Ÿ"""
        community_scores = {}
        
        for author, stats in contributors.items():
            if stats['community_help'] > 0:
                # ç¤¾å€å¹«åŠ©æ¬Šé‡
                score = stats['community_help'] * 1.0 + stats['issues'] * 0.5
                community_scores[author] = {
                    'score': score,
                    'help_score': stats['community_help'],
                    'issues_created': stats['issues']
                }
        
        if not community_scores:
            return None
        
        winner = max(community_scores.items(), key=lambda x: x[1]['score'])
        
        return {
            'winner': winner[0],
            'score': winner[1]['score'],
            'details': winner[1],
            'category': 'community_star'
        }
    
    def _evaluate_consistency_award(self, contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸æŒçºŒè²¢ç»ç"""
        consistency_scores = {}
        
        for author, stats in contributors.items():
            # åŸºæ–¼ç¸½è²¢ç»æ•¸å’Œä¸€è‡´æ€§
            total_contributions = stats['prs'] + stats['issues']
            if total_contributions >= 3:  # è‡³å°‘3å€‹è²¢ç»
                # ä¸€è‡´æ€§åˆ†æ•¸ = ç¸½è²¢ç»æ•¸ + åˆä½µç‡åŠ åˆ†
                merge_rate = (stats['merged_prs'] / stats['prs']) if stats['prs'] > 0 else 0
                score = total_contributions + merge_rate * 2.0
                
                consistency_scores[author] = {
                    'score': score,
                    'total_contributions': total_contributions,
                    'merge_rate': merge_rate
                }
        
        if not consistency_scores:
            return None
        
        winner = max(consistency_scores.items(), key=lambda x: x[1]['score'])
        
        return {
            'winner': winner[0],
            'score': winner[1]['score'],
            'details': winner[1],
            'category': 'consistency_champion'
        }
    
    def _evaluate_collaboration_award(self, contributors: Dict, analysis: Dict) -> Optional[Dict]:
        """è©•é¸å”ä½œè‹±é›„ç"""
        # é€™å€‹çé …éœ€è¦æ›´è¤‡é›œçš„åˆ†æï¼Œæš«æ™‚åŸºæ–¼ç¸½è²¢ç»åˆ†æ•¸
        collaboration_scores = {}
        
        for author, stats in contributors.items():
            # åŸºæ–¼å¤šæ¨£æ€§è²¢ç»ï¼ˆä¸åŒé¡å‹çš„è²¢ç»ï¼‰
            diversity_score = sum([
                1 if stats['story_content'] > 0 else 0,
                1 if stats['technical_improvements'] > 0 else 0,
                1 if stats['bug_fixes'] > 0 else 0,
                1 if stats['ui_improvements'] > 0 else 0,
                1 if stats['community_help'] > 0 else 0
            ])
            
            if diversity_score >= 2:  # è‡³å°‘2ç¨®ä¸åŒé¡å‹çš„è²¢ç»
                score = diversity_score * 1.5 + stats['total_score'] * 0.1
                collaboration_scores[author] = {
                    'score': score,
                    'diversity_score': diversity_score,
                    'total_score': stats['total_score']
                }
        
        if not collaboration_scores:
            return None
        
        winner = max(collaboration_scores.items(), key=lambda x: x[1]['score'])
        
        return {
            'winner': winner[0],
            'score': winner[1]['score'],
            'details': winner[1],
            'category': 'collaboration_hero'
        }
    
    def _generate_award_report(self, awards: Dict, analysis: Dict) -> str:
        """ç”Ÿæˆçé …å ±å‘Š"""
        period = analysis['period']
        overall = analysis['overall_stats']
        
        report = f"""# ğŸ† Tsext Adventure æœˆåº¦è²¢ç»çç²çè€…

## ğŸ“… è©•é¸æœŸé–“
**é–‹å§‹æ—¥æœŸ**: {period['start_date']}  
**çµæŸæ—¥æœŸ**: {period['end_date']}  
**è©•é¸å¤©æ•¸**: {period['days']} å¤©

## ğŸ“Š æœ¬æœŸçµ±è¨ˆ
- **ç¸½è²¢ç»è€…**: {overall['active_contributors']} äºº
- **ç¸½ PR æ•¸**: {overall['total_prs']} å€‹
- **ç¸½ Issue æ•¸**: {overall['total_issues']} å€‹
- **PR åˆä½µç‡**: {overall['pr_merge_rate']:.1f}%

## ğŸ‰ ç²çè€…åå–®

"""
        
        # ç”Ÿæˆå„çé …ç²çè€…
        for award_id, award_data in awards.items():
            award_config = self.award_categories[award_id]
            winner = award_data['winner']
            score = award_data['score']
            details = award_data['details']
            
            report += f"### {award_config['name']}\n"
            report += f"**ç²çè€…**: @{winner}\n"
            report += f"**è©•é¸æ¨™æº–**: {award_config['description']}\n"
            report += f"**è©•é¸åˆ†æ•¸**: {score:.2f}\n"
            
            # æ·»åŠ è©³ç´°ä¿¡æ¯
            if award_id == 'best_story':
                report += f"**æ•…äº‹å…§å®¹ PR**: {details['story_count']} å€‹\n"
            elif award_id == 'technical_innovation':
                report += f"**æŠ€è¡“æ”¹é€² PR**: {details['tech_count']} å€‹\n"
            elif award_id == 'bug_hunter':
                report += f"**Bug ä¿®å¾© PR**: {details['bug_count']} å€‹\n"
            elif award_id == 'design_master':
                report += f"**UI æ”¹é€² PR**: {details['ui_count']} å€‹\n"
            elif award_id == 'community_star':
                report += f"**ç¤¾å€å¹«åŠ©åˆ†æ•¸**: {details['help_score']:.1f}\n"
            elif award_id == 'consistency_champion':
                report += f"**ç¸½è²¢ç»æ•¸**: {details['total_contributions']} å€‹\n"
            elif award_id == 'collaboration_hero':
                report += f"**è²¢ç»å¤šæ¨£æ€§**: {details['diversity_score']} ç¨®é¡å‹\n"
            
            report += "\n"
        
        # æ·»åŠ ç‰¹åˆ¥æ„Ÿè¬
        report += f"""## ğŸ™ ç‰¹åˆ¥æ„Ÿè¬

æ„Ÿè¬æ‰€æœ‰åœ¨æœ¬æœˆç‚º Tsext Adventure åšå‡ºè²¢ç»çš„é–‹ç™¼è€…å€‘ï¼

### æ‰€æœ‰è²¢ç»è€…
"""
        
        contributors = analysis['contributor_stats']
        sorted_contributors = sorted(
            contributors.items(),
            key=lambda x: x[1]['total_score'],
            reverse=True
        )
        
        for author, stats in sorted_contributors:
            report += f"- **@{author}** - {stats['total_score']:.1f} åˆ† "
            report += f"({stats['prs']} PRs, {stats['issues']} Issues)\n"
        
        report += f"""
## ğŸ¯ ä¸‹æœˆç›®æ¨™

è®“æˆ‘å€‘ç¹¼çºŒåŠªåŠ›ï¼Œç‚º Tsext Adventure å‰µé€ æ›´å¤šç²¾å½©å…§å®¹ï¼

- ğŸ­ æ›´å¤šå‰µæ„æ•…äº‹å…§å®¹
- ğŸ› ï¸ æŒçºŒæŠ€è¡“æ”¹é€²
- ğŸ› ç©æ¥µä¿®å¾©å•é¡Œ
- ğŸ¨ å„ªåŒ–ç”¨æˆ¶é«”é©—
- ğŸŒŸ åŠ å¼·ç¤¾å€äº’å‹•

---

*è©•é¸æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*  
*Tsext Adventure è‡ªå‹•è©•é¸ç³»çµ±*
"""
        
        return report
    
    def save_awards(self, awards_data: Dict, filename: Optional[str] = None) -> str:
        """ä¿å­˜çé …æ•¸æ“š"""
        if not filename:
            timestamp = datetime.now().strftime('%Y_%m_%d')
            filename = f"monthly_awards_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(awards_data, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"çé …æ•¸æ“šå·²ä¿å­˜åˆ°: {filename}")
        return filename
    
    def save_award_report(self, report: str, filename: Optional[str] = None) -> str:
        """ä¿å­˜çé …å ±å‘Š"""
        if not filename:
            timestamp = datetime.now().strftime('%Y_%m')
            filename = f"monthly_awards_{timestamp}.md"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"çé …å ±å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename


def main():
    """ä¸»å‡½æ•¸"""
    # è¨­å®šå€‰åº«è³‡è¨Š
    OWNER = "BabyGrootCICD"
    REPO = "Sext-Adventure"
    
    try:
        # åˆå§‹åŒ–çé …ç³»çµ±
        github_api = GitHubAPI()
        award_system = AwardSystem(github_api, OWNER, REPO)
        
        # è©•é¸æœˆåº¦çé …
        logger.info("é–‹å§‹æœˆåº¦çé …è©•é¸...")
        awards_data = award_system.evaluate_monthly_awards(30)
        
        # ä¿å­˜çµæœ
        awards_file = award_system.save_awards(awards_data)
        report_file = award_system.save_award_report(awards_data['report'])
        
        # è¼¸å‡ºæ‘˜è¦
        awards = awards_data['awards']
        print(f"\nğŸ† æœˆåº¦çé …è©•é¸å®Œæˆ!")
        print(f"ğŸ“Š è©•é¸çé …æ•¸: {len(awards)}")
        
        for award_id, award_data in awards.items():
            award_config = award_system.award_categories[award_id]
            print(f"ğŸ‰ {award_config['name']}: @{award_data['winner']}")
        
        print(f"ğŸ“‹ çé …æ•¸æ“š: {awards_file}")
        print(f"ğŸ“„ çé …å ±å‘Š: {report_file}")
        
    except Exception as e:
        logger.error(f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        raise


if __name__ == "__main__":
    main()
